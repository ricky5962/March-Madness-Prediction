# March-Madness-Prediction
Predict the outcomes of this year's US men's college basketball tournament using a combination of rich historical data and machine learning algorithm.

# Overview
The model is based on two unique sets of probabilities generated by using a point spread-based model, and the other one based on efficiency metrics and Four Factors.

Point Spread: A predicted difference in total points scored between the visiting and the home team, which has been proven to be the easiest and most useful predictors. Las Vegas always wins.  We extracted the point spread from every Division I men’s basketball contest since 2002-2003 season with game results.

Integrated variables that take the four perspective that highly influential to a basketball team’s success.

Four Factors of Basketball Success:
•	Shooting
•	Turnovers
•	Rebounding 
•	Free Throws

The models is evaluated using Logarithmic Loss(Log Loss)

What is Logarithmic Loss (Log Loss)?
The accuracy of each group’s prediction will be measured by Log-Loss in the FBAS March Data Crunch Madness Competition. An understanding of how this metric is calculated and how it should be interpreted is important for competitors to optimize their chances of winning.
Log-Loss measures the accuracy of a classifier.The loss function quantifies the amount by which the prediction deviates from the actual value. In the case of the March Madness competition, Log-Loss will put a number to how well - on average - a group is able to predict the probability of Team A winning a game over Team B. Thus, Log-Loss is useful when your research objective is not only to say if an object belongs to class A or class B, but to also provide the probability of each outcome. The ultimate goal is to minimize Log-Loss: a perfect classifier would have a Log-Loss of exactly zero. 
If there are only 2 classes (which is true in the case of March Madness - one of two teams can which each game), Log Loss is defined as:
Log Loss =  
Where:
•	N is the number of games played 
•	Pi is a group’s predicted probability of Team 1 beating Team 2 (in a specific game)
•	Yi is 1 if Team 1 wins and 0 if Team 2 wins
Again, the smaller the Log-Loss the better. Games which are not played are ignored in the scoring. The use of the logarithm provides extreme punishments for being both confident and wrong. In the worst possible case, a prediction that something is true when it is actually false will add infinite to your error score. In order to prevent this, predictions are bounded away from the extremes by a small value. 


